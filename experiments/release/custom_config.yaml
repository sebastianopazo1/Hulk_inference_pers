# det: 0 #3
# pose: 1 #8
# parsing: 2 #18
# caption: 3 #7

common:  # prefix
  is_training: False
  share_backbone_group:              [0,  0,  0, 0]
  share_decoder_group:               [0,  0,  0, 0]
  # use modality groups to control the communication of neck, adapter, and output proj
  share_rgb_group:                   [0,  0,  0, 0] #rgb
  share_dense_labeling_group:        [-1, 0, 0, -1] #dense_labeling
  share_text_group:                  [-1, -1, -1, 0]  # text
  share_sparse_labeling_group:       [0, -1, -1, -1]
  share_video_group:                 [-1, -1, -1, -1]  # share modality is truly the share task group, e.g., parsing datasets share a group
  share_modality_group:              [4, 5, 6, 1]

  model_entry_type: aio_entry_v2mae_shareneck
  model_entry_kwargs:
    test_flag: [null, pose, par_flip, image_caption]
    flip_channels: [[14, 15], [16, 17], [18, 19]]


  auto_denan: False

  workers: 2
  random_seed: 233

  use_ceph: True
  sync: True
  collate: det

# task_specific_param = ['backbone', 'neck', 'decoder', 'dataset', 'sampler', 'lr_scheduler', 'optimizer']
tasks :  # prefix

  0:
    name: Peddet
    loss_weight: 15
    gres_ratio: 8  # int, > 0, = Task_GPUs / (world_Size/sum(all_gres_ratios))
    dataset:
      type: PedestrainDetectionDataset_v2  # train for 150 epochs
      kwargs:
        task_spec:
          img_folder:
            - /mnt/path...to.../PedDet2d/CrowdHuman/Images
          ann_file:
            - /mnt/path...to.../PedDet2d/CrowdHuman/annotations/train.json
          return_masks: False
        augmentation:
            max_size: 1120
        vit: True
        num_append_fake_boxes: 867
        return_box_xyxy: True
        append_z: True
    sampler:
      batch_size: 4  # per card
      shuffle_strategy: 1
      batch_accumulation: 1

    backbone:
      type: vit_base_patch16_mask
      kwargs:
        task_sp_list: [ 'rel_pos_h', 'rel_pos_w' ] # wrong list would somehow cause .cuda() stuck without error
        pretrained: True
        lms_checkpoint_train: fairscale
        window: False
        test_pos_mode: learnable_interpolate
        learnable_pos: True
        drop_path_rate: 0.2
        attn_calcul_method: 'math'
        vis_patch_token_ratio: 1
        vis_label_token_ratio: 0.

    patch_neck:
      type: MAEdecoder_proj_neck
      kwargs:
        mask_dim: 256
        modality: rgb

    label_neck:
      type: MAEdecoder_proj_neck
      kwargs:
        mask_dim: 256
        modality: sparse_labeling

    patch_adapter:
      type: rgb_adapter
      kwargs:
        pretrained: True
        stride_level: 1
        in_chans: 3
        learnable_pos: False
        use_abs_pos_emb: True
        test_pos_mode: interpolate_with_nomask
        img_size: 1344 # dynamic input size: TODO: nested
        round_padding: True  #  should fix in rgb
        pad_attn_mask: True
        task_sp_list: [ 'pos_embed' ]

    label_adapter:
      type: sparse_labeling_adapter
      kwargs:
        pretrained: True
        in_chans: 3  # xyz
        num_joints: 867 # boxes with random gts
        num_frames: 2   # 2 for x1y1 and x2y2
        embed_dim: 768
        patch_size: [ 2, 1 ]
        stride_level: [ 1, 1 ]
        use_abs_pos_emb: True
        learnable_pos: False
        test_pos_mode: learnable_interpolate
        type_embed: False
        proj_norm: 'LN'
        task_sp_list: [ 'pos_embed',
                        'text_embedding',
                        'proj_kernel',
                        'proj',
                        'merge_kernel',
        ]

    patch_proj:
      type: rgb_projector
      kwargs:
        loss_cfg:
          type: MaskedMSELoss
          kwargs:
            stride: 1
            norm_pix_loss: True
            pix_loss: True
            pix_loss_weight: 1.
            norm_pix_loss_weight: 1.

    label_proj:
      type: sparse_labeling_projector
      kwargs:
        task_sp_list: [ 'text_vectors',  # useless
                        'text_features',
        ]
        modality_share_list: [
          'text_vectors',  # useless
          'output_proj',
          'translate_weight',
          'translate_bias',
          'post_mul_norm',
          'patch_proj',
          'class_proj'
        ]
        in_chans: 3
        num_joints: 867 # boxes with random gts
        num_frames: 2   # 2 for x1y1 and x2y2
        pre_proj_type: fix_text_tokens
        num_classes: 1
        reference_type: four_points
        box_mlp: True
        replace_post_mul_norm: True
        translate_weight_scale: 4
        text_prototype: True
        loss_cfg:
          type: MaskDetFocalDiceLoss
          kwargs:
            cfg:
              deep_supervision: True
              focal_alpha: 0.25
              class_weight: 2.0
              bbox_weight: 5.0
              giou_weight: 2.
              ign_thr: 0.7
              dec_layers: 9
              num_classes: 1
              predict3d: True
              xyxy: True

    decoder:
      type: UniHCPv2_Head
      kwargs:
        predictor: 'hulk'
        task: recons
        modality_share_list: ['predictor.mask_token']
        task_sp_list: [
                        'predictor.query_embed_patch',
                        'predictor.query_embed_label',
                        'predictor.anchor',
                        'predictor.class_embed','predictor.fc_bias',    # useless in Hulk
        ] # wrong list would somehow cause .cuda() stuck without error
        loss_weight: 1.0
        transformer_predictor_cfg:
          hidden_dim: 256
          num_queries: 20 # useless in Hulk
          nheads: 8
          dim_feedforward: 2048
          dec_layers: 9
          pre_norm: False
          arch: fan_in
          enforce_input_project: False
          mask_on: False
          num_feature_levels: 1
          cross_pos_embed: anchor
          patch_pos_mode: interpolate_with_nomask
          label_pos_mode: simple_interpolate
          self_attn_mask_type: patch_diag_label_row_nested
          adding_per_layer_pe: True
          mask_token_normal_init: True
          intermediate_output: True
          peddet_cfgs:
            share_content_query: 3
            num_queries: 867
            pre_defined_path: '289_points_3d.npy'
            query_pe_dim: 3
            xattn: False
            anchor_requires_grad: False

        loss_cfg:
          type: CEL_Sigmoid


  1:
    name: cocopose_256x192
    loss_weight: 28000
    gres_ratio: 3  # int, > 0, = Task_GPUs / (world_Size/sum(all_gres_ratios))
    backbone:
      type: vit_base_patch16_mask
      kwargs:
        task_sp_list: [ 'rel_pos_h', 'rel_pos_w' ] # wrong list would somehow cause .cuda() stuck without error
        pretrained: True
        lms_checkpoint_train: fairscale
        window: False
        test_pos_mode: False # when torch.compile is True, this should be False
        learnable_pos: True
        drop_path_rate: 0.2
        img_size: 1344
        num_encoded_tokens: 192
        vis_patch_token_ratio: 1
        vis_label_token_ratio: 0.

    dataset:
      type: COCOPosDatasetDev
      kwargs:
        ann_file: /mnt/path...to.../pose_public/coco/annotations/person_keypoints_train2017.json
        img_prefix: /mnt/path...to.../pose_public/coco/train2017/
        use_udp: True
        data_use_ratio: 1
        data_cfg: {
                    'image_size':[192, 256],
                    'heatmap_size':[48, 64], # originally, 'heatmap_size':[48, 64]
                    'num_output_channels': 17,
                    'num_joints': 17,
                    'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],],
                    'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],
                    'soft_nms': False,
                    'nms_thr': 1.0,
                    'oks_thr': 0.9,
                    'vis_thr': 0.2,
                    'use_gt_bbox': False,
                    'det_bqbox_thr': 0.0,
                    'bbox_file': './COCO_val2017_detections_AP_H_56_person.json'
                }
    sampler:
      batch_size: 176  # per card
      shuffle_strategy: 1

    patch_neck:
      type: MAEdecoder_proj_neck
      kwargs:
        mask_dim: 256    # project to 256 dim for decoder
        modality: rgb    # patch modality

    label_neck:
      type: MAEdecoder_proj_neck
      kwargs:
        mask_dim: 256   # project to 256 dim for decoder
        modality: dense_labeling  # label modality

    patch_adapter:
      type: rgb_adapter  # change to adapter_rgb
      kwargs:
        pretrained: True
        stride_level: 1
        in_chans: 3  # 3 for rgb
        learnable_pos: False  # fixed position embedding, redundant parameter
        test_pos_mode: False  # PE parameters are interpolated from mae to 'img_size'/16, then use repeat(batchsize, 1, 1)
        img_size: [  256, 192 ]
        task_sp_list: [ 'pos_embed' ]

    label_adapter: # for supervised training, the results of label adapter is useless
      type: dense_labeling_adapter
      kwargs:
        pretrained: True
        stride_level: 1
        in_chans: 17   # class num
        learnable_pos: False
        test_pos_mode: False
        img_size: [  256, 192 ]
        dim_class_embed: 64  # embedding shape for class embedding. TODO: chance to text features
        emb_padding_idx: 255  #
        task_sp_list: [ 'pos_embed',
                        'class_embed',]

    # fix kwargs of the project, which should be the same as that in the adapter, such as
    # hidden_dim, patch_size, in_chans, stride_level are set in the solver - create_modal
    patch_proj:
      type: rgb_projector
      kwargs:
        loss_cfg:
          type: MaskedMSELoss
          kwargs:
            stride: 1
            norm_pix_loss: True
            pix_loss: True
            pix_loss_weight: 1.
            norm_pix_loss_weight: 1.


    label_proj:
      type: dense_labeling_projector
      kwargs:
        task_sp_list: [ 'post_mul_norm',
                        'loss_fn',
                         'upsample_network',
                         'text_features',]
        emb_padding_idx: 255 # should be the same with that in the input adapter
        post_mul_norm: True
        replace_post_mul_norm: False   # replace the post_mul_norm(LN) with a linear layer
        translate_weight_scale: 1
        cls_loss_branch: True
        description_dict_name: ./experiments/release/checked_pose_coco_name # this key is only valid when we set text_prototype to be True
        upsample_hidden_dim: 256
        task: pose
        loss_cfg:
          type: POS_FocalDiceLoss_bce_cls_emb
          kwargs:
            target_type: GaussianHeatMap
            cfg:
              num_classes: 17
              deep_supervision: True
              ignore_blank: False
              class_weight: 0.001
              dice_weight: 0.0
              mask_weight: 1.0
              redundant_queries: 1
              dec_layers: 9
              sample_weight: [ 0.38647058, 0.33606767, 0.33835369, 0.29253424, 0.29636332,
                               0.4987484 , 0.49978854, 0.39467358, 0.40091822, 0.36039853,
                               0.36918446, 0.43343303, 0.4345989 , 0.32999829, 0.33092793,
                               0.27714171, 0.27754939 ]
              eos_coef: 0.1

    decoder:
      type: UniHCPv2_Head
      kwargs:
        predictor: 'hulk'
        task: recons
        modality_share_list: ['predictor.mask_token']
        task_sp_list: [
                        'predictor.query_embed_patch',
                        'predictor.query_embed_label',
                        'predictor.class_embed', 'predictor.fc_bias',   # useless in Hulk
        ] # wrong list would somehow cause .cuda() stuck without error
        loss_weight: 1.0
        transformer_predictor_cfg:
          hidden_dim: 256
          num_queries: 20  # useless in Hulk
          nheads: 8
          dim_feedforward: 2048
          dec_layers: 9
          pre_norm: False # indicate to use pre_norm or post_norm in (self-attn, FFN)
          arch: fan_in # fan_in type to init the weights
          enforce_input_project: False  # placeholder, useless in Hulk
          mask_on: False # placeholder, useless in Hulk
          intermediate_output: True
          num_feature_levels: 1  # placeholder, useless in Hulk
          cross_pos_embed: anchor # indicate to use adaptive pose2d. should always be "anchor" in Hulk
          cls_out_dim: 1  # placeholder, useless in Hulk
          patch_pos_mode: False # Mode to generate pos_embed for patch tokens in decoder.
                                              # given the fixed self.query_embed_patch (which has a same shape of that in adapter),
                                              # repeat(batchsize, 1,1)
          label_pos_mode: False
          self_attn_mask_type: full                            # full for all attention
                                                               # type of mask for self-attention,
                                                               # shape [patch_tokens(rgb), label_tokens(sparse_labeling), fixed text tokens]
          detach_from_peddet: True
          adding_per_layer_pe: True  # whether to add per-layer pe to the input of each decoder layer
          use_adapt_pos2d: True
        loss_cfg:
          type: CEL_Sigmoid

  2:
    name: CIHP_parsing
    loss_weight: 3.6
    gres_ratio: 4  # int, > 0, = Task_GPUs / (world_Size/sum(all_gres_ratios))
    dataset:
      type: CIHPParsingDataset  # train for 150 epochs
      kwargs:
        data_path: /mnt/path...to.../parsing_public/CIHP # #sh1424:s3://parsing_public/human3.6 #/mnt/lustre/share/wangyizhou/human3.6 #sh1984:s3://seg_public/human3.6
        cfg:
          stride_level: 1
          is_flip: True
          crop_size: [ 480, 480 ]
          is_multi_scale: True
          scale_factor: 11
          center_crop_test: False
          base_size: 480
          eval_crop_size: [ 480, 480 ]
          ignore2endclass: True

          is_photometricdistortion: True
          brightness: 32
          contrast_range: [ 0.5, 1.5 ]
          saturation_range: [ 0.5, 1.5 ]
          hue_delta: 18
          is_rotate: True

          ignore_value: 255 # duplicated with decoder.kwargs.ignore_value
          num_classes: 20
          label_list: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 ]

    sampler:
      batch_size: 26  # per card
      shuffle_strategy: 1

    backbone:
      type: vit_base_patch16_mask
      kwargs:
        task_sp_list: [ 'rel_pos_h', 'rel_pos_w' ] # wrong list would somehow cause .cuda() stuck without error
        pretrained: True
        lms_checkpoint_train: fairscale
        window: False
        test_pos_mode: learnable_interpolate
        learnable_pos: True
        drop_path_rate: 0.2
        vis_patch_token_ratio: 1
        vis_label_token_ratio: 0.

    patch_neck:
      type: MAEdecoder_proj_neck
      kwargs:
        mask_dim: 256
        modality: rgb


    label_neck:
      type: MAEdecoder_proj_neck
      kwargs:
        mask_dim: 256
        modality: dense_labeling

    patch_adapter:
      type: rgb_adapter  # change to adapter_rgb
      kwargs:
        pretrained: True
        stride_level: 1
        in_chans: 3
        learnable_pos: False
        test_pos_mode: False
        img_size: 480
        task_sp_list: [ 'pos_embed' ]

    label_adapter:
      type: dense_labeling_adapter
      kwargs:
        pretrained: True
        stride_level: 1
        in_chans: 20
        learnable_pos: False
        test_pos_mode: False
        img_size: 480
        dim_class_embed: 64
        emb_padding_idx: 255
        task_sp_list: [ 'pos_embed', 'class_embed', ]

    patch_proj:
      type: rgb_projector
      kwargs:
        loss_cfg:
          type: MaskedMSELoss
          kwargs:
            stride: 1
            norm_pix_loss: True
            pix_loss: True
            pix_loss_weight: 1.
            norm_pix_loss_weight: 1.

    label_proj:
      type: dense_labeling_projector
      kwargs: # kept one
        task_sp_list: [ 'post_mul_norm',
                        'loss_fn', 'text_features' ]
        modality_share_list: ['upsample_network',]
        emb_padding_idx: 255 # should be the same with that in the input adapter
        post_mul_norm: True
        replace_post_mul_norm: False   # replace the post_mul_norm(LN) with a linear layer
        translate_weight_scale: 1  # scale the translate weight to 6 times of the original value(1), NOTE that we should
        description_dict_name: ./experiments/release/checked_par_cihp_name # this key is only valid when we set text_prototype to be True
        cls_loss_branch: True
        task: parsing
        upsample_before_product: True
        upsample_hidden_dim: 256   #dim of hidden features in upsampling network
        loss_cfg:
          type: FocalDiceLoss_bce_cls_emb_sample_weight #POS_FocalDiceLoss_bce_cls_emb
          kwargs:
            cfg: #for maskedsetloss v2
              ignore_index: 20
              loss_weight: 1.
              loss_per_class: True
              dice_weight: 50.0
              mask_weight: 50.0
              class_weight: 0.1
              deep_supervision: True
              dec_layers: 9
              cls_weight_sample: True
              sample_weight: [ 1.0, 0.25279349, 0.97595474, 0.06368458, 0.08419378,
                               0.91287129, 0.18341584, 0.50346535, 0.12729844, 0.6937058,
                               0.96898868, 0.07022631, 0.07464639, 0.99359972, 0.88490099,
                               0.88490099, 0.27644979000000003, 0.27644979000000003, 0.33016266, 0.33016266 ] #follow v1 parsing
    decoder:
      type: UniHCPv2_Head
      kwargs:
        predictor: 'hulk'
        task: recons
        modality_share_list: ['predictor.mask_token']
        task_sp_list: [
                        'predictor.query_embed_patch',
                        'predictor.query_embed_label',
                         'predictor.class_embed','predictor.fc_bias',    # useless in Hulk
        ] # wrong list would somehow cause .cuda() stuck without error
        loss_weight: 1.0
        transformer_predictor_cfg:
          hidden_dim: 256
          num_queries: 20
          nheads: 8
          dim_feedforward: 2048
          dec_layers: 9
          pre_norm: False
          arch: fan_in
          enforce_input_project: False
          mask_on: False
          intermediate_output: True
          num_feature_levels: 1
          cross_pos_embed: anchor
          cls_out_dim: 1
          patch_pos_mode: False # Mode to generate pos_embed for patch tokens in decoder.
          label_pos_mode: False
          self_attn_mask_type: patch_diag_label_row_textlabelfull # type of mask for self-attention,
          # shape [patch_tokens(rgb), label_tokens(sparse_labeling), fixed text tokens]
          detach_from_peddet: True  # Not use the peddet_cfgs to modify the model structure
          adding_per_layer_pe: True  # whether to add per-layer pe to the input of each decoder layer
          use_adapt_pos2d: True

        loss_cfg:
          type: FocalDiceLoss_bce_cls_emb_sample_weight
          kwargs:
            cfg:
              deep_supervision: True
              no_object_weight: 0.1

              class_weight: 0.25
              dice_weight: 5.0
              mask_weight: 5.0
              redundant_queries: 1
              num_points: 12544

              dec_layers: 6

              oversample_ratio: 3.0
              importance_sample_ratio: 0.75
              sample_weight: [ 1.0, 0.25279349, 0.97595474, 0.06368458, 0.08419378,
                               0.91287129, 0.18341584, 0.50346535, 0.12729844, 0.6937058,
                               0.96898868, 0.07022631, 0.07464639, 0.99359972, 0.88490099,
                               0.88490099, 0.27644979000000003, 0.27644979000000003, 0.33016266, 0.33016266 ]

  3:
    name: image_caption_joint
    loss_weight: 90
    gres_ratio: 3  # int, > 0, = Task_GPUs / (world_Size/sum(all_gres_ratios))
    dataset:
      type: CocoCaption
      kwargs:
        bert_dir: /mnt/path...to.../Hulk/experiments/release/bert-base-uncased
        max_words: 40
        img_size: 384
        prompt: ''
        split_type: train
        joint_train: True
        joint_train_anno_root: /mnt/path...to.../textreid/joint_reid_caption_train.json
        synth_peds_root: /mnt/path...to.../textreid/SYNTH-PEDES/
        cuhk_peds_root: /mnt/path...to.../textreid/CUHK-PEDES/imgs/
        mals_root: /mnt/path...to.../textreid/MALS
        luperson_root: /mnt/path...to.../textreid/LUPerson-T/imgs/

    sampler:
      batch_size: 100  # per card
      shuffle_strategy: 1

    backbone:
      type: vit_base_patch16_mask
      kwargs:
        task_sp_list: [ 'rel_pos_h', 'rel_pos_w' ] # wrong list would somehow cause .cuda() stuck without error
        pretrained: True
        lms_checkpoint_train: fairscale
        window: False
        test_pos_mode: learnable_interpolate
        learnable_pos: True
        drop_path_rate: 0.2

        vis_patch_token_ratio: 1
        vis_label_token_ratio: 0.

    patch_neck:
      type: MAEdecoder_proj_neck
      kwargs:
        mask_dim: 256
        modality: rgb

    label_neck:
      type: MAEdecoder_proj_neck
      kwargs:
        mask_dim: 256
        modality: text

    patch_adapter:
      type: rgb_adapter  # change to adapter_rgb
      kwargs:
        pretrained: True
        stride_level: 1
        in_chans: 3
        learnable_pos: False
        test_pos_mode: False
        img_size: [ 384, 384 ]
        task_sp_list: [ 'pos_embed' ]

    label_adapter:
      type: text_adapter
      kwargs:
        image_caption: True
        pretrained: True
        max_tokens: 40
        task_sp_list: [ ]

    # fix kwargs of the project, which should be the same as that in the adapter, such as
    # hidden_dim, patch_size, in_chans, stride_level are set in the solver - create_modal
    patch_proj:
      type: rgb_projector
      kwargs:
        loss_cfg:
          type: MaskedMSELoss
          kwargs:
            stride: 1
            norm_pix_loss: True
            pix_loss: True
            pix_loss_weight: 1.
            norm_pix_loss_weight: 1.

    label_proj:
      type: text_projector
      kwargs:
        description_dict_name: ./experiments/release/caption_bert
        image_caption: True
        one_way_semantics: True
        post_mul_norm: True
        loss_cfg:
          type: LabelSmoothingCrossEntropy
          kwargs:
            epsilon: 0.1
            loss_weight: 1.
        task_sp_list: [ 'post_mul_norm',
                        'text_vectors',
                        'loss_fn']

    decoder:
      type: UniHCPv2_Head
      kwargs:
        predictor: 'hulk'
        task: recons
        modality_share_list: ['predictor.mask_token']
        task_sp_list: [
                        'predictor.query_embed_patch',
                        'predictor.query_embed_label',
                        'predictor.mask_token_buffer',
                        'predictor.mask_token_proj',
                        'predictor.captiontoken_ln',
                        'predictor.class_embed','predictor.fc_bias',    # useless in Hulk
        ] # wrong list would somehow cause .cuda() stuck without error
        loss_weight: 1.0
        transformer_predictor_cfg:
          hidden_dim: 256
          num_queries: 20
          nheads: 8
          dim_feedforward: 2048
          dec_layers: 9
          pre_norm: False
          arch: fan_in
          enforce_input_project: False
          mask_on: False
          num_feature_levels: 1
          cross_pos_embed: anchor
          cls_out_dim: 1
          self_attn_mask_type: caption_mask
          caption_cfgs: { nn.parameter: True, vocal_size: 30522, lndo: True ,bert_feats_for_embedding: True }
          mask_token_normal_init: True
          detach_from_peddet: True
        loss_cfg:
          type: CEL_Sigmoid

